{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "off_train = pd.read_csv(\"./data/ccf_offline_stage1_train.csv\",header=None)\n",
    "off_train.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "# print len(off_train) #1754884\n",
    "# len(set(off_train.user_id))#539438\n",
    "# len(set(off_train.coupon_id))#9739\n",
    "off_test = pd.read_csv('./data/ccf_offline_stage1_test_revised.csv',header=None)\n",
    "off_test.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received']\n",
    "on_train = pd.read_csv('./data/ccf_online_stage1_train.csv',header=None)\n",
    "on_train.columns = ['user_id','merchant_id','action','coupon_id','discount_rate','date_received','date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分测试集、验证集和训练集\n",
    "                (date_received)，领取优惠券日期          领取优惠券日期和使用优惠券日期  \n",
    "                \n",
    "测试集           dateset3: 20160701~20160731 (113640),features3 from 20160315~20160630  (off_test)  \n",
    "验证集           dateset2: 20160515~20160615 (258446),features2 from 20160201~20160514    \n",
    "训练集           dateset1: 20160414~20160514 (138303),features1 from 20160101~20160413     \n",
    "分为提取特征区间（领取优惠券日期和使用优惠券在20160315-20160630）和预测区间（领取优惠券日期在20160701-20160730）  \n",
    "***\n",
    "`预测区间`是指特定的**领取优惠券日期**\n",
    "`特征区间`是值特定的**领取优惠券日期和消费优惠券日期**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset3 = off_test\n",
    "feature3 = off_train[((off_train.date>='20160315')&(off_train.date<='20160630'))|((off_train.date=='null')&(off_train.date_received>='20160315')&(off_train.date_received<='20160630'))]\n",
    "dataset2 = off_train[(off_train.date_received>='20160515')&(off_train.date_received<='20160615')]\n",
    "feature2 = off_train[(off_train.date>='20160201')&(off_train.date<='20160514')|((off_train.date=='null')&(off_train.date_received>='20160201')&(off_train.date_received<='20160514'))]\n",
    "dataset1 = off_train[(off_train.date_received>='20160414')&(off_train.date_received<='20160514')]\n",
    "feature1 = off_train[(off_train.date>='20160101')&(off_train.date<='20160413')|((off_train.date=='null')&(off_train.date_received>='20160101')&(off_train.date_received<='20160413'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取其他特征\n",
    "#### 用户与优惠券的交互特征\n",
    "* 1.用户领取所有优惠券数目  \n",
    "* 2.用户领取相同优惠券数目\n",
    "* 3.用户领取相同优惠券的第一次\n",
    "* 4.用户领取相同优惠权的最后一次\n",
    "* 5.该天领取的所有优惠券数目\n",
    "* 6.该天领取相同优惠券的数目\n",
    "* 7,用户上一次下一次领取优惠券的间隔\n",
    "* this_month_user_receive_all_coupon_count\n",
    "* this_month_user_receive_same_coupon_count\n",
    "* this_month_user_receive_same_coupon_lastone\n",
    "* this_month_user_receive_same_coupon_firstone\n",
    "* this_day_user_receive_all_coupon_count\n",
    "* this_day_user_receive_same_coupon_count\n",
    "* day_gap_before, day_gap_after  (receive the same coupon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116204, 11)\n"
     ]
    }
   ],
   "source": [
    "#用户该月领取所有优惠券的张数\n",
    "t = dataset3[['user_id']]#两个中括号最后取出的类型是dataframe   76309x2\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('user_id').agg('sum').reset_index() #reset_index()将groupby之后的index还原成初始状态，获得用户领取所有优惠券的张数\n",
    "\n",
    "#用户该月领取相同优惠券的张数\n",
    "t1 = dataset3[['user_id','coupon_id']]\n",
    "t1['this_month_user_receive_same_count'] = 1\n",
    "t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()#groupby\n",
    "\n",
    "#用户领取相同优惠券的张数大于1的情况下，最大日期和最小日期\n",
    "t2 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t2.date_received = t2.date_received.astype('str')\n",
    "t2 = t2.groupby(['user_id','coupon_id']).agg(lambda x:':'.join(x)).reset_index() #将领取相同优惠券的所有日期连接接起来\n",
    "t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "t2 = t2[t2.receive_number>1]#只取出领取相同优惠券大于1张\n",
    "t2['max_date_received'] = t2.date_received.apply(lambda s:max(int(d) for d in s.split(':')))\n",
    "t2['min_date_received'] = t2.date_received.apply(lambda s:min(int(d) for d in s.split(':')))\n",
    "t2 = t2[['user_id','coupon_id','max_date_received','min_date_received']] #3394x4\n",
    "\n",
    "\n",
    "#用户第一次或最后一次领取优惠券（1），用户只领取一张优惠券（-1），用户领取多张优惠券（0）\n",
    "t3 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')#113640x5 按照原始键user_id和coupon_id进行合并，按照笛卡尔积的形式\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received - t3.min_date_received\n",
    "# 这时t3有非常多的NAN\n",
    "def is_firstlastone(x): #判断是否是第一次或最后一次领取优惠券\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    elif x > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1#代表只领取了一张优惠券\n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "# t3  113640x5\n",
    "\n",
    "#用户在一天领取所有优惠券的张数\n",
    "t4 = dataset3[['user_id','date_received']] #针对的是线下预测数据领取优惠券后是否后消费，因洗date_received都不为空\n",
    "t4['this_day_user_receive_all_coupon_count'] = 1 #同一user_id,有多少相同date_received，就代表改天总共领取了多少张优惠券\n",
    "t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "#用户在一天领取相同优惠券的张数\n",
    "t5 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "#用户领取相同优惠券的所有日期，用:连接\n",
    "t6 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6 = t6.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "\n",
    "#得到和上一次和下一次领取优惠券日期的最短间隔,首先得到用户领取相同优惠券的所有日期，再将当前日期与所有日期比较\n",
    "#用户上一次和下一次领取相同优惠券的间隔\n",
    "def get_day_gap_before(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap > 0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "def get_day_gap_after(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "        if this_gap > 0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "t7 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "\n",
    "t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "t7['day_gap_before'] = t7['date_received_date'].apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7['date_received_date'].apply(get_day_gap_after)\n",
    "t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "other_feature3 = pd.merge(t1,t,on='user_id')\n",
    "other_feature3 = pd.merge(other_feature3,t3,on=['user_id','coupon_id'])\n",
    "other_feature3 = pd.merge(other_feature3,t4,on=['user_id','date_received'])\n",
    "other_feature3 = pd.merge(other_feature3,t5,on=['user_id','coupon_id','date_received'])\n",
    "other_feature3 = pd.merge(other_feature3,t7,on=['user_id','coupon_id','date_received'])\n",
    "other_feature3.to_csv('data/other_feature3.csv',index=None)\n",
    "print other_feature3.shape #116204x11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 对于dataset2提取相同特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262240, 11)\n"
     ]
    }
   ],
   "source": [
    "t = dataset2[['user_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t1 = dataset2[['user_id','coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "t2 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t2.date_received = t2.date_received.astype('str')\n",
    "t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t2['receive_number'] = 1\n",
    "t2 = t2[t2.receive_number>1]\n",
    "t2['max_date_received'] = t2.date_received.apply(lambda s:max([int(d) for d in s.split(':')]))\n",
    "t2['min_date_received'] = t2.date_received.apply(lambda s:min([int(d) for d in s.split(':')]))\n",
    "t2 = t2[['user_id','coupon_id','max_date_received','min_date_received']]\n",
    "\n",
    "t3 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received.astype('int')\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype('int') - t3.min_date_received\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #those only receive once\n",
    "        \n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "\n",
    "t4 = dataset2[['user_id','date_received']]\n",
    "t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t5 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t6 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6 = t6.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "        \n",
    "def get_day_gap_after(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "\n",
    "t7 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "\n",
    "t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "other_feature2 = pd.merge(t1,t,on='user_id')\n",
    "other_feature2 = pd.merge(other_feature2,t3,on=['user_id','coupon_id'])\n",
    "other_feature2 = pd.merge(other_feature2,t4,on=['user_id','date_received'])\n",
    "other_feature2 = pd.merge(other_feature2,t5,on=['user_id','coupon_id','date_received'])\n",
    "other_feature2 = pd.merge(other_feature2,t7,on=['user_id','coupon_id','date_received'])\n",
    "other_feature2.to_csv('data/other_feature2.csv',index=None)\n",
    "print other_feature2.shape#262240,11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于dataset1提取相同特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139785, 11)\n"
     ]
    }
   ],
   "source": [
    "#for dataset1\n",
    "t = dataset1[['user_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t1 = dataset1[['user_id','coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "t2 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t2.date_received = t2.date_received.astype('str')\n",
    "t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "t2 = t2[t2.receive_number>1]\n",
    "t2['max_date_received'] = t2.date_received.apply(lambda s:max([int(d) for d in s.split(':')]))\n",
    "t2['min_date_received'] = t2.date_received.apply(lambda s:min([int(d) for d in s.split(':')]))\n",
    "t2 = t2[['user_id','coupon_id','max_date_received','min_date_received']]\n",
    "\n",
    "t3 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received.astype('int')\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype('int') - t3.min_date_received\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #those only receive once\n",
    "        \n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "t4 = dataset1[['user_id','date_received']]\n",
    "t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t5 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t6 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6 = t6.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "        \n",
    "def get_day_gap_after(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "\n",
    "t7 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "other_feature1 = pd.merge(t1,t,on='user_id')\n",
    "other_feature1 = pd.merge(other_feature1,t3,on=['user_id','coupon_id'])\n",
    "other_feature1 = pd.merge(other_feature1,t4,on=['user_id','date_received'])\n",
    "other_feature1 = pd.merge(other_feature1,t5,on=['user_id','coupon_id','date_received'])\n",
    "other_feature1 = pd.merge(other_feature1,t7,on=['user_id','coupon_id','date_received'])\n",
    "other_feature1.to_csv('data/other_feature1.csv',index=None)\n",
    "print other_feature1.shape #（139785,11）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优惠券相关特征\n",
    "* 折扣率\n",
    "* 折扣最低消费额\n",
    "* 折扣满减额\n",
    "* 是否是满减类型优惠\n",
    "* 相同优惠券总张数\n",
    "* \n",
    "*       discount_rate. discount_man. discount_jian. is_man_jian\n",
    "*       day_of_week,day_of_month. (date_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def calc_discount_rate(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return float(s[0]) #直接就是折扣率\n",
    "    else:\n",
    "        return 1.0 - float(s[1])/float(s[0])\n",
    "\n",
    "def get_discount_man(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[0])\n",
    "    \n",
    "def get_discount_jian(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[1])\n",
    "\n",
    "def is_man_jian(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 0 #不是满减类型\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "#dataset3\n",
    "dataset3['day_of_week'] = dataset3.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset3['day_of_month'] = dataset3.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset3['days_distance'] = dataset3.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,6,30)).days)\n",
    "dataset3['discount_man'] = dataset3.discount_rate.apply(get_discount_man)\n",
    "dataset3['discount_jian'] = dataset3.discount_rate.apply(get_discount_jian)\n",
    "dataset3['is_man_jian'] = dataset3.discount_rate.apply(is_man_jian)\n",
    "dataset3['discount_rate'] = dataset3.discount_rate.apply(calc_discount_rate)\n",
    "d = dataset3[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset3 = pd.merge(dataset3,d,on='coupon_id',how='left')\n",
    "dataset3.to_csv('data/coupon3_feature.cdv',index=None)\n",
    "\n",
    "#dataset2\n",
    "dataset2['day_of_week'] = dataset2.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset2['day_of_month'] = dataset2.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset2['days_distance'] = dataset2.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,5,14)).days)\n",
    "dataset2['discount_man'] = dataset2.discount_rate.apply(get_discount_man)\n",
    "dataset2['discount_jian'] = dataset2.discount_rate.apply(get_discount_jian)\n",
    "dataset2['is_man_jian'] = dataset2.discount_rate.apply(is_man_jian)\n",
    "dataset2['discount_rate'] = dataset2.discount_rate.apply(calc_discount_rate)\n",
    "d = dataset2[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset2 = pd.merge(dataset2,d,on='coupon_id',how='left')\n",
    "dataset2.to_csv('data/coupon2_feature.csv',index=None)\n",
    "\n",
    "#dataset1\n",
    "dataset1['day_of_week'] = dataset1.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset1['day_of_month'] = dataset1.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset1['days_distance'] = dataset1.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,4,13)).days)\n",
    "dataset1['discount_man'] = dataset1.discount_rate.apply(get_discount_man)\n",
    "dataset1['discount_jian'] = dataset1.discount_rate.apply(get_discount_jian)\n",
    "dataset1['is_man_jian'] = dataset1.discount_rate.apply(is_man_jian)\n",
    "dataset1['discount_rate'] = dataset1.discount_rate.apply(calc_discount_rate)\n",
    "d = dataset1[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset1 = pd.merge(dataset1,d,on='coupon_id',how='left')\n",
    "dataset1.to_csv('data/coupon1_feature.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 商家相关特征\n",
    "*      total_sales. sales_use_coupon.  total_coupon\n",
    "*      coupon_rate = sales_use_coupon/total_sales.  \n",
    "*      transfer_rate = sales_use_coupon/total_coupon. \n",
    "*      merchant_avg_distance,merchant_min_distance,merchant_max_distance of those use coupon\n",
    "  \n",
    "* 这里对feature三个月的数据进行特征提取，分别是feature3  feature2  feature1  \n",
    "* 1.所有不重复的商家\n",
    "* 2.商户总的到店消费量，包括领取优惠券并消费与没有领取优惠券并消费\n",
    "* 3.商户中领取优惠券并且到店消费的用户数量\n",
    "* 4.商户被领优惠券的总数量\n",
    "* 5.商户中领取优惠券并到店消费的用户的最小距离、最大距离、平均距离、中位数距离\n",
    "* 6.优惠券转化率，领取优惠券并到店消费的几率，到店消费并使用优惠券/总的优惠券数\n",
    "* 7.优惠券消费率，到店消费并使用优惠券的几率，到店消费并使用优惠券/总的到店消费数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#for feature3\n",
    "merchant3 = feature3[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "#得到所有不重复的merchant_id\n",
    "t = merchant3[['merchant_id']] \n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "#商户总的到店消费量，包括领取优惠券并消费与没有领取优惠券并消费\n",
    "t1 = merchant3[merchant3.date!='null'][['merchant_id']] #先切片得到满足要求的所有所有列，然后再选取列merchant_id\n",
    "t1['total_sales'] = 1\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "#商户中领取优惠券并且到店消费的用户数量\n",
    "t2 = merchant3[(merchant3.date!='null')&(merchant3.date_received!='null')][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "#商户被领优惠券的总数量\n",
    "t3 = merchant3[merchant3.coupon_id!='null'][['merchant_id']]\n",
    "t3['total_coupon']=1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "#商户中领取优惠券并到店消费的用户的最小距离、最大距离、平均距离、中位数距离\n",
    "t4 = merchant3[(merchant3.date!='null')&(merchant3.coupon_id!='null')][['merchant_id','distance']]\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "#处理null值方法：初始情况的类型都是object,先将null代替为-1,之后改为整型，在将-1重新代替为np.nan，才能对距离处理\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "merchant3_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t2,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t3,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t5,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t6,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t7,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t8,on='merchant_id',how='left')\n",
    "\n",
    "merchant3_feature.sales_use_coupon = merchant3_feature.sales_use_coupon.replace(np.nan,0)\n",
    "#优惠券转化率，领取优惠券并到店消费的几率，到店消费并使用优惠券/总的优惠券数\n",
    "#优惠券消费率，到店消费并使用优惠券的几率，到店消费并使用优惠券/总的到店消费数\n",
    "merchant3_feature['merchant_coupon_transfer_rate'] = merchant3_feature.sales_use_coupon.astype('float')/merchant3_feature.total_coupon\n",
    "merchant3_feature['coupon_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_sales\n",
    "merchant3_feature.total_coupon = merchant3_feature.total_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant3_feature.to_csv('data/merchant3_feature.csv',index=None)\n",
    "\n",
    "#for feature2\n",
    "merchant2 = feature2[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "t = merchant2[['merchant_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = merchant2[merchant2.date!='null'][['merchant_id']]\n",
    "t1['total_sales'] = 1\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t2 = merchant2[(merchant2.date!='null')&(merchant2.coupon_id!='null')][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t3 = merchant2[merchant2.coupon_id!='null'][['merchant_id']]\n",
    "t3['total_coupon'] = 1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t4 = merchant2[(merchant2.date!='null')&(merchant2.coupon_id!='null')][['merchant_id','distance']]\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "merchant2_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t2,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t3,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t5,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t6,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t7,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t8,on='merchant_id',how='left')\n",
    "merchant2_feature.sales_use_coupon = merchant2_feature.sales_use_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant2_feature['merchant_coupon_transfer_rate'] = merchant2_feature.sales_use_coupon.astype('float') / merchant2_feature.total_coupon\n",
    "merchant2_feature['coupon_rate'] = merchant2_feature.sales_use_coupon.astype('float') / merchant2_feature.total_sales\n",
    "merchant2_feature.total_coupon = merchant2_feature.total_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant2_feature.to_csv('data/merchant2_feature.csv',index=None)\n",
    "\n",
    "#for feature1\n",
    "merchant1 = feature1[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "t = merchant1[['merchant_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = merchant1[merchant1.date!='null'][['merchant_id']]\n",
    "t1['total_sales'] = 1\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t2 = merchant1[(merchant1.date!='null')&(merchant1.coupon_id!='null')][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t3 = merchant1[merchant1.coupon_id!='null'][['merchant_id']]\n",
    "t3['total_coupon'] = 1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t4 = merchant1[(merchant1.date!='null')&(merchant1.coupon_id!='null')][['merchant_id','distance']]\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "\n",
    "merchant1_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t2,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t3,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t5,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t6,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t7,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t8,on='merchant_id',how='left')\n",
    "merchant1_feature.sales_use_coupon = merchant1_feature.sales_use_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant1_feature['merchant_coupon_transfer_rate'] = merchant1_feature.sales_use_coupon.astype('float') / merchant1_feature.total_coupon\n",
    "merchant1_feature['coupon_rate'] = merchant1_feature.sales_use_coupon.astype('float') / merchant1_feature.total_sales\n",
    "merchant1_feature.total_coupon = merchant1_feature.total_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant1_feature.to_csv('data/merchant1_feature.csv',index=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户相关特征\n",
    "      count_merchant.   \n",
    "      user_avg_distance, user_min_distance,user_max_distance.   \n",
    "      buy_use_coupon. buy_total. coupon_received.  \n",
    "      buy_use_coupon/coupon_received.   \n",
    "      buy_use_coupon/buy_total  \n",
    "      user_date_datereceived_gap  \n",
    "* 针对feature3 feature2 feature1\n",
    "  用户消费情况下，用户消费的商家总数  \n",
    "  用户领取优惠券并消费，用户离商家距离,最小距离，平均距离，最大距离，中位数距离  \n",
    "  用户到店消费并使用优惠券的张数\n",
    "  用户消费的总次数\n",
    "  用户领取优惠券的总张数  \n",
    "  用户领取优惠券和消费优惠券的日期间隔，最短间隔、最大间隔、平均间隔\n",
    "  用户使用优惠券几率，使用优惠券消费/消费总次数\n",
    "  用户领取优惠券的转化率，使用优惠券消费/优惠券总张数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def get_user_date_datereceived_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "\n",
    "#for feature3\n",
    "user3 = feature3[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user3[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "#用户消费情况下，用户消费的商家总数\n",
    "t1 = user3[user3.date!='null'][['user_id','merchant_id']]\n",
    "t1.merchant_id = 1\n",
    "t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "#用户领取优惠券并消费，用户离商家距离,最小距离，平均距离，最大距离，中位数距离\n",
    "t2=user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "#用户到店消费并使用优惠券的张数\n",
    "t7 = user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon']=1\n",
    "t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "#用户消费的总次数\n",
    "t8 = user3[user3.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "#用户领取优惠券的总张数\n",
    "t9 = user3[user3.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received']=1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "#用户领取优惠券和消费优惠券的日期间隔\n",
    "t10 = user3[(user3.date_received!='null')&(user3.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap']=t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user3_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t3,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t4,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t5,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t6,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t7,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t8,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t9,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t11,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t12,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t13,on='user_id',how='left')\n",
    "user3_feature.count_merchant = user3_feature.count_merchant.replace(np.nan,0)\n",
    "user3_feature.buy_use_coupon = user3_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user3_feature['buy_use_coupon_rate'] = user3_feature.buy_use_coupon.astype('float')/user3_feature.buy_total.astype('float')\n",
    "user3_feature['user_coupon_transfer_rate'] = user3_feature.buy_use_coupon.astype('float')/user3_feature.coupon_received.astype('float')\n",
    "user3_feature.buy_total = user3_feature.buy_total.replace(np.nan,0)\n",
    "user3_feature.coupon_received = user3_feature.coupon_received.replace(np.nan,0)\n",
    "user3_feature.to_csv('data/user3_feature.csv',index=None)\n",
    "\n",
    "#for feature2\n",
    "user2 = feature2[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user2[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user2[user2.date!='null'][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user2[(user2.date!='null')&(user2.coupon_id!='null')][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user2[(user2.date!='null')&(user2.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t8 = user2[user2.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user2[user2.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user2[(user2.date_received!='null')&(user2.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user2_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t3,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t4,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t5,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t6,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t7,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t8,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t9,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t11,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t12,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t13,on='user_id',how='left')\n",
    "user2_feature.count_merchant = user2_feature.count_merchant.replace(np.nan,0)\n",
    "user2_feature.buy_use_coupon = user2_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user2_feature['buy_use_coupon_rate'] = user2_feature.buy_use_coupon.astype('float') / user2_feature.buy_total.astype('float')\n",
    "user2_feature['user_coupon_transfer_rate'] = user2_feature.buy_use_coupon.astype('float') / user2_feature.coupon_received.astype('float')\n",
    "user2_feature.buy_total = user2_feature.buy_total.replace(np.nan,0)\n",
    "user2_feature.coupon_received = user2_feature.coupon_received.replace(np.nan,0)\n",
    "user2_feature.to_csv('data/user2_feature.csv',index=None)\n",
    "\n",
    "\n",
    "#for feature1\n",
    "user1 = feature1[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user1[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user1[user1.date!='null'][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user1[(user1.date!='null')&(user1.coupon_id!='null')][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user1[(user1.date!='null')&(user1.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t8 = user1[user1.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user1[user1.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user1[(user1.date_received!='null')&(user1.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user1_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t3,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t4,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t5,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t6,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t7,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t8,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t9,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t11,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t12,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t13,on='user_id',how='left')\n",
    "user1_feature.count_merchant = user1_feature.count_merchant.replace(np.nan,0)\n",
    "user1_feature.buy_use_coupon = user1_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user1_feature['buy_use_coupon_rate'] = user1_feature.buy_use_coupon.astype('float') / user1_feature.buy_total.astype('float')\n",
    "user1_feature['user_coupon_transfer_rate'] = user1_feature.buy_use_coupon.astype('float') / user1_feature.coupon_received.astype('float')\n",
    "user1_feature.buy_total = user1_feature.buy_total.replace(np.nan,0)\n",
    "user1_feature.coupon_received = user1_feature.coupon_received.replace(np.nan,0)\n",
    "user1_feature.to_csv('data/user1_feature.csv',index=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户商户的交互特征\n",
    "* times_user_buy_merchant_before.\n",
    "* feature3 fefature2 feature1\n",
    "* 不重复的用户商户对\n",
    "* 用户到同一商家消费的次数\n",
    "* 用户到同一商家领取优惠券的总张数\n",
    "* 用户商家的所有对\n",
    "* 用户到店普通消费的次数\n",
    "* 用户到商家领取优惠券并消费的转化率 消费/优惠券总张数\n",
    "* 用户到商家领取优惠券并消费的消费率 消费/总的消费次数\n",
    "* 用户到商家的消费率\n",
    "* 用户到商家的普通消费率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/hl/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#for feature3\n",
    "all_user_merchant = feature3[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "#用到同一商家消费的次数\n",
    "t = feature3[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t.groupby(['user_id','merchant_id']).agg('sum').reset_index()#由于没有去除重复的对，所以t中有重复的对\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "#用户领取同一商家优惠券张数\n",
    "t1 = feature3[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "#用户领取优惠券并到店消费的次数\n",
    "t2 = feature3[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "#用户商户对\n",
    "t3 = feature3[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index() #491819\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "#用户到店普通消费的次数\n",
    "t4 = feature3[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant3 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_received.astype('float')\n",
    "user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / user_merchant3.user_merchant_any.astype('float')\n",
    "user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3.to_csv('data/user_merchant3.csv',index=None)\n",
    "\n",
    "\n",
    "#feature2\n",
    "all_user_merchant = feature2[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature2[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature2[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature2[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature2[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature2[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant2 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2.user_merchant_buy_use_coupon = user_merchant2.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant2.user_merchant_buy_common = user_merchant2.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant2['user_merchant_coupon_transfer_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_received.astype('float')\n",
    "user_merchant2['user_merchant_coupon_buy_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2['user_merchant_rate'] = user_merchant2.user_merchant_buy_total.astype('float') / user_merchant2.user_merchant_any.astype('float')\n",
    "user_merchant2['user_merchant_common_buy_rate'] = user_merchant2.user_merchant_buy_common.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2.to_csv('data/user_merchant2.csv',index=None)\n",
    "\n",
    "#for feature1\n",
    "all_user_merchant = feature1[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature1[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature1[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature1[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature1[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature1[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant1 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1.user_merchant_buy_use_coupon = user_merchant1.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant1.user_merchant_buy_common = user_merchant1.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant1['user_merchant_coupon_transfer_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_received.astype('float')\n",
    "user_merchant1['user_merchant_coupon_buy_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1['user_merchant_rate'] = user_merchant1.user_merchant_buy_total.astype('float') / user_merchant1.user_merchant_any.astype('float')\n",
    "user_merchant1['user_merchant_common_buy_rate'] = user_merchant1.user_merchant_buy_common.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1.to_csv('data/user_merchant1.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 产生训练数据集和测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if s[0]=='null':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "coupon3 = pd.read_csv('data/coupon3_feature.csv') #dataset3\n",
    "merchant3 = pd.read_csv('data/merchant3_feature.csv') #feature3\n",
    "user3 = pd.read_csv('data/user3_feature.csv') #feature3\n",
    "user_merchant3 = pd.read_csv('data/user_merchant3.csv') #feature3\n",
    "other_feature3 = pd.read_csv('data/other_feature3.csv') #dataset3\n",
    "dataset3 = pd.merge(coupon3,merchant3,on='merchant_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user3,on='user_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user_merchant3,on=['user_id','merchant_id'],how='left')\n",
    "dataset3 = pd.merge(dataset3,other_feature3,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "print dataset3.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
